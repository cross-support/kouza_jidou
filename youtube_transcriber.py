#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YouTubeå‹•ç”»æ–‡å­—èµ·ã“ã—ãƒ„ãƒ¼ãƒ« - å·¥ç¨‹1B

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€YouTubeå‹•ç”»ã®URLã‹ã‚‰å­—å¹•ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•å–å¾—ã—ã€
è¬›åº§ä½œæˆã®ãŸã‚ã®ãƒªã‚µãƒ¼ãƒãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚
"""

import argparse
import json
import sys
import re
from datetime import datetime
from typing import List, Dict, Optional

try:
    from youtube_transcript_api import YouTubeTranscriptApi
    from youtube_transcript_api.formatters import TextFormatter
except ImportError as e:
    print(f"Error: Required library not found: {e}", file=sys.stderr)
    print("Please install required library:", file=sys.stderr)
    print("  pip3 install youtube-transcript-api", file=sys.stderr)
    sys.exit(1)


class YouTubeTranscriber:
    """YouTubeå‹•ç”»ã®æ–‡å­—èµ·ã“ã—ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""

    def __init__(self, language_codes: List[str] = None):
        """
        åˆæœŸåŒ–

        Args:
            language_codes: å–å¾—ã™ã‚‹å­—å¹•ã®è¨€èªã‚³ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ['ja', 'en']ï¼‰
        """
        self.language_codes = language_codes or ['ja', 'en']
        self.formatter = TextFormatter()

    def extract_video_id(self, url: str) -> Optional[str]:
        """
        YouTube URLã‹ã‚‰å‹•ç”»IDã‚’æŠ½å‡º

        Args:
            url: YouTubeå‹•ç”»ã®URL

        Returns:
            å‹•ç”»IDï¼ˆæŠ½å‡ºã§ããªã„å ´åˆã¯Noneï¼‰
        """
        # æ§˜ã€…ãªYouTube URLãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¯¾å¿œ
        patterns = [
            r'(?:https?:\/\/)?(?:www\.)?youtube\.com\/watch\?v=([^&]+)',
            r'(?:https?:\/\/)?(?:www\.)?youtu\.be\/([^?]+)',
            r'(?:https?:\/\/)?(?:www\.)?youtube\.com\/embed\/([^?]+)',
            r'(?:https?:\/\/)?(?:www\.)?youtube\.com\/v\/([^?]+)',
        ]

        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)

        # URLã§ã¯ãªãç›´æ¥å‹•ç”»IDãŒæ¸¡ã•ã‚ŒãŸå ´åˆ
        if re.match(r'^[a-zA-Z0-9_-]{11}$', url):
            return url

        return None

    def get_transcript(self, video_id: str) -> Optional[Dict]:
        """
        å‹•ç”»IDã‹ã‚‰å­—å¹•ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

        Args:
            video_id: YouTubeå‹•ç”»ID

        Returns:
            å­—å¹•ãƒ‡ãƒ¼ã‚¿ã®è¾æ›¸ï¼ˆå–å¾—ã§ããªã„å ´åˆã¯Noneï¼‰
        """
        try:
            print(f"  ğŸ“¹ å‹•ç”»ID: {video_id}")

            # YouTubeTranscriptApiã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
            ytt_api = YouTubeTranscriptApi()

            # å­—å¹•ãƒªã‚¹ãƒˆã‚’å–å¾—
            transcript_list = ytt_api.list(video_id)

            # å­—å¹•ã‚’å–å¾—ï¼ˆè¨€èªã‚³ãƒ¼ãƒ‰ã®å„ªå…ˆé †ä½ã§è©¦è¡Œï¼‰
            transcript = None
            used_language = None

            # ã¾ãšæŒ‡å®šã•ã‚ŒãŸè¨€èªã§å­—å¹•ã‚’æ¢ã™
            try:
                transcript = transcript_list.find_transcript(self.language_codes)
                used_language = transcript.language_code
                print(f"  âœ“ å­—å¹•ã‚’å–å¾—: {used_language}")
            except Exception as e:
                print(f"  - æŒ‡å®šè¨€èªã§è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {str(e)[:50]}...")

                # åˆ©ç”¨å¯èƒ½ãªå­—å¹•ã‚’è¡¨ç¤º
                available_langs = [t.language_code for t in transcript_list]
                print(f"  â„¹ åˆ©ç”¨å¯èƒ½ãªå­—å¹•: {', '.join(available_langs)}")

            if not transcript:
                print(f"  âœ— å­—å¹•ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆå¯¾å¿œè¨€èª: {', '.join(self.language_codes)}ï¼‰", file=sys.stderr)
                return None

            # å­—å¹•ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            fetched_transcript = transcript.fetch()

            # ã‚¹ãƒ‹ãƒšãƒƒãƒˆã®ãƒªã‚¹ãƒˆã‚’å–å¾—
            snippets = list(fetched_transcript.snippets)

            # ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
            text = ' '.join([snippet.text for snippet in snippets])

            # å­—å¹•ã®è©³ç´°æƒ…å ±ã‚’ä¿æŒ
            segments = []
            for snippet in snippets:
                segments.append({
                    'start': snippet.start,
                    'duration': snippet.duration,
                    'text': snippet.text
                })

            return {
                'video_id': video_id,
                'language': used_language,
                'text': text,
                'word_count': len(text),
                'segments': segments,
                'total_duration': segments[-1]['start'] + segments[-1]['duration'] if segments else 0
            }

        except Exception as e:
            print(f"  âœ— ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
            return None

    def transcribe_videos(self, video_urls: List[str]) -> Dict:
        """
        è¤‡æ•°ã®å‹•ç”»ã‚’æ–‡å­—èµ·ã“ã—

        Args:
            video_urls: YouTubeå‹•ç”»URLã®ãƒªã‚¹ãƒˆ

        Returns:
            æ–‡å­—èµ·ã“ã—çµæœã®è¾æ›¸
        """
        print("=" * 60)
        print("ğŸ¬ YouTubeå‹•ç”»æ–‡å­—èµ·ã“ã— - å·¥ç¨‹1B")
        print("=" * 60)
        print(f"ğŸ“‹ å¯¾è±¡å‹•ç”»æ•°: {len(video_urls)}")

        results = []

        for i, url in enumerate(video_urls, 1):
            print(f"\n[{i}/{len(video_urls)}] å‡¦ç†ä¸­...")
            print(f"  ğŸ”— URL: {url[:60]}...")

            # å‹•ç”»IDã‚’æŠ½å‡º
            video_id = self.extract_video_id(url)
            if not video_id:
                print(f"  âœ— ç„¡åŠ¹ãªURL", file=sys.stderr)
                continue

            # å­—å¹•ã‚’å–å¾—
            transcript = self.get_transcript(video_id)
            if transcript:
                transcript['source_url'] = url
                results.append(transcript)

        # çµæœã‚’ã¾ã¨ã‚ã‚‹
        transcription_data = {
            'transcription_date': datetime.now().isoformat(),
            'source_type': 'youtube',
            'total_videos': len(video_urls),
            'successful_transcriptions': len(results),
            'success_rate': f"{len(results)}/{len(video_urls)} ({len(results)/len(video_urls)*100:.1f}%)" if video_urls else "0/0",
            'transcriptions': results,
            'summary': {
                'total_words': sum(t['word_count'] for t in results),
                'total_duration': sum(t['total_duration'] for t in results),
                'average_words_per_video': sum(t['word_count'] for t in results) // len(results) if results else 0,
                'languages_used': list(set(t['language'] for t in results))
            }
        }

        return transcription_data

    def save_to_json(self, data: Dict, output_path: str):
        """
        ãƒ‡ãƒ¼ã‚¿ã‚’JSONå½¢å¼ã§ä¿å­˜

        Args:
            data: ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
        except Exception as e:
            print(f"\nâœ— ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)


def main():
    parser = argparse.ArgumentParser(
        description='YouTubeå‹•ç”»æ–‡å­—èµ·ã“ã—ãƒ„ãƒ¼ãƒ« - è¬›åº§ä½œæˆã®ãŸã‚ã®ãƒªã‚µãƒ¼ãƒãƒ‡ãƒ¼ã‚¿åé›†'
    )

    # URLãƒªã‚¹ãƒˆæ–¹å¼ã¨ç›´æ¥URLæŒ‡å®šã®é¸æŠ
    input_group = parser.add_mutually_exclusive_group(required=True)
    input_group.add_argument(
        '--url-list',
        help='YouTube URLãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆ1è¡Œã«1URLï¼‰'
    )
    input_group.add_argument(
        '--urls',
        nargs='+',
        help='YouTubeå‹•ç”»ã®URLï¼ˆè¤‡æ•°æŒ‡å®šå¯ï¼‰'
    )

    parser.add_argument(
        '--languages',
        nargs='+',
        default=['ja', 'en'],
        help='å–å¾—ã™ã‚‹å­—å¹•ã®è¨€èªã‚³ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ja enï¼‰'
    )
    parser.add_argument(
        '--output',
        default='youtube_transcripts.json',
        help='å‡ºåŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: youtube_transcripts.jsonï¼‰'
    )

    args = parser.parse_args()

    # URLãƒªã‚¹ãƒˆã‚’å–å¾—
    if args.url_list:
        try:
            with open(args.url_list, 'r', encoding='utf-8') as f:
                video_urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]

            if not video_urls:
                print("Error: URLãƒªã‚¹ãƒˆãŒç©ºã§ã™", file=sys.stderr)
                sys.exit(1)

        except FileNotFoundError:
            print(f"Error: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.url_list}", file=sys.stderr)
            sys.exit(1)
        except Exception as e:
            print(f"Error: {e}", file=sys.stderr)
            sys.exit(1)
    else:
        video_urls = args.urls

    # æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œ
    transcriber = YouTubeTranscriber(language_codes=args.languages)
    transcription_data = transcriber.transcribe_videos(video_urls)

    # çµæœã‚’ä¿å­˜
    transcriber.save_to_json(transcription_data, args.output)

    # ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
    print("\n" + "=" * 60)
    print("ğŸ“Š æ–‡å­—èµ·ã“ã—å®Œäº†ã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    print(f"å¯¾è±¡å‹•ç”»æ•°: {transcription_data['total_videos']}")
    print(f"æˆåŠŸç‡: {transcription_data['success_rate']}")
    print(f"ç·æ–‡å­—æ•°: {transcription_data['summary']['total_words']:,}æ–‡å­—")
    print(f"ç·å†ç”Ÿæ™‚é–“: {transcription_data['summary']['total_duration']:.1f}ç§’ ({transcription_data['summary']['total_duration']/60:.1f}åˆ†)")

    if transcription_data['successful_transcriptions'] > 0:
        print(f"å¹³å‡æ–‡å­—æ•°: {transcription_data['summary']['average_words_per_video']:,}æ–‡å­—/å‹•ç”»")
        print(f"ä½¿ç”¨è¨€èª: {', '.join(transcription_data['summary']['languages_used'])}")

    print("=" * 60)


if __name__ == '__main__':
    main()
