#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çµ±åˆãƒªã‚µãƒ¼ãƒãƒ„ãƒ¼ãƒ« - å·¥ç¨‹1A + 1B

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€Webãƒªã‚µãƒ¼ãƒï¼ˆå·¥ç¨‹1Aï¼‰ã¨YouTubeæ–‡å­—èµ·ã“ã—ï¼ˆå·¥ç¨‹1Bï¼‰ã‚’
1ã¤ã®ã‚³ãƒãƒ³ãƒ‰ã§å®Ÿè¡Œã—ã€è¬›åº§ä½œæˆã®ãŸã‚ã®åŒ…æ‹¬çš„ãªãƒªã‚µãƒ¼ãƒãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ã¾ã™ã€‚
"""

import argparse
import json
import sys
import subprocess
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional


class UnifiedResearchTool:
    """çµ±åˆãƒªã‚µãƒ¼ãƒãƒ„ãƒ¼ãƒ«"""

    def __init__(self):
        self.script_dir = Path(__file__).parent

    def run_web_research(self, url_list: str, output: str) -> Optional[Dict]:
        """
        Webãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œï¼ˆå·¥ç¨‹1Aï¼‰

        Args:
            url_list: Webã®URLãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
            output: å‡ºåŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«å

        Returns:
            ãƒªã‚µãƒ¼ãƒçµæœã®è¾æ›¸ï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
        """
        print("=" * 60)
        print("ğŸ“š å·¥ç¨‹1A: Webãƒªã‚µãƒ¼ãƒã‚’é–‹å§‹")
        print("=" * 60)

        script_path = self.script_dir / "course_research.py"

        if not script_path.exists():
            print(f"âœ— ã‚¨ãƒ©ãƒ¼: course_research.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", file=sys.stderr)
            return None

        try:
            # course_research.py ã‚’å®Ÿè¡Œ
            result = subprocess.run(
                [
                    sys.executable,
                    str(script_path),
                    "--url-list", url_list,
                    "--output", output
                ],
                capture_output=True,
                text=True,
                check=True
            )

            print(result.stdout)
            if result.stderr:
                print(result.stderr, file=sys.stderr)

            # ç”Ÿæˆã•ã‚ŒãŸJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            with open(output, 'r', encoding='utf-8') as f:
                return json.load(f)

        except subprocess.CalledProcessError as e:
            print(f"âœ— Webãƒªã‚µãƒ¼ãƒå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
            if e.stdout:
                print(e.stdout)
            if e.stderr:
                print(e.stderr, file=sys.stderr)
            return None
        except FileNotFoundError as e:
            print(f"âœ— ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
            return None
        except json.JSONDecodeError as e:
            print(f"âœ— JSONè§£æã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
            return None

    def run_youtube_research(self, url_list: str, output: str, languages: list = None) -> Optional[Dict]:
        """
        YouTubeæ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œï¼ˆå·¥ç¨‹1Bï¼‰

        Args:
            url_list: YouTubeã®URLãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
            output: å‡ºåŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«å
            languages: å­—å¹•è¨€èªã‚³ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆ

        Returns:
            æ–‡å­—èµ·ã“ã—çµæœã®è¾æ›¸ï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
        """
        print("\n" + "=" * 60)
        print("ğŸ¥ å·¥ç¨‹1B: YouTubeæ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹")
        print("=" * 60)

        script_path = self.script_dir / "youtube_transcriber.py"

        if not script_path.exists():
            print(f"âœ— ã‚¨ãƒ©ãƒ¼: youtube_transcriber.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", file=sys.stderr)
            return None

        try:
            # youtube_transcriber.py ã‚’å®Ÿè¡Œ
            cmd = [
                sys.executable,
                str(script_path),
                "--url-list", url_list,
                "--output", output
            ]

            if languages:
                cmd.extend(["--languages"] + languages)

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                check=True
            )

            print(result.stdout)
            if result.stderr:
                print(result.stderr, file=sys.stderr)

            # ç”Ÿæˆã•ã‚ŒãŸJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            with open(output, 'r', encoding='utf-8') as f:
                return json.load(f)

        except subprocess.CalledProcessError as e:
            print(f"âœ— YouTubeæ–‡å­—èµ·ã“ã—å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
            if e.stdout:
                print(e.stdout)
            if e.stderr:
                print(e.stderr, file=sys.stderr)
            return None
        except FileNotFoundError as e:
            print(f"âœ— ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
            return None
        except json.JSONDecodeError as e:
            print(f"âœ— JSONè§£æã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
            return None

    def generate_summary(self, web_data: Optional[Dict], youtube_data: Optional[Dict]) -> Dict:
        """
        çµ±åˆã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ

        Args:
            web_data: Webãƒªã‚µãƒ¼ãƒãƒ‡ãƒ¼ã‚¿
            youtube_data: YouTubeæ–‡å­—èµ·ã“ã—ãƒ‡ãƒ¼ã‚¿

        Returns:
            çµ±åˆã‚µãƒãƒªãƒ¼ã®è¾æ›¸
        """
        summary = {
            'unified_research_date': datetime.now().isoformat(),
            'web_research': {
                'status': 'success' if web_data else 'failed',
                'sources': web_data.get('total_sources', 0) if web_data else 0,
                'characters': web_data.get('summary', {}).get('total_characters', 0) if web_data else 0
            },
            'youtube_research': {
                'status': 'success' if youtube_data else 'failed',
                'videos': youtube_data.get('successful_transcriptions', 0) if youtube_data else 0,
                'characters': youtube_data.get('summary', {}).get('total_words', 0) if youtube_data else 0,
                'duration_minutes': youtube_data.get('summary', {}).get('total_duration', 0) / 60 if youtube_data else 0
            },
            'total': {
                'total_sources': (
                    (web_data.get('total_sources', 0) if web_data else 0) +
                    (youtube_data.get('successful_transcriptions', 0) if youtube_data else 0)
                ),
                'total_characters': (
                    (web_data.get('summary', {}).get('total_characters', 0) if web_data else 0) +
                    (youtube_data.get('summary', {}).get('total_words', 0) if youtube_data else 0)
                )
            }
        }
        return summary

    def print_summary(self, summary: Dict):
        """ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        print("\n" + "=" * 60)
        print("ğŸ“Š çµ±åˆãƒªã‚µãƒ¼ãƒå®Œäº†ã‚µãƒãƒªãƒ¼")
        print("=" * 60)

        # Webãƒªã‚µãƒ¼ãƒ
        web = summary['web_research']
        status_icon = "âœ“" if web['status'] == 'success' else "âœ—"
        print(f"\nğŸ“š Webãƒªã‚µãƒ¼ãƒ: {status_icon} {web['status'].upper()}")
        if web['status'] == 'success':
            print(f"  - æƒ…å ±æº: {web['sources']}ä»¶")
            print(f"  - æ–‡å­—æ•°: {web['characters']:,}æ–‡å­—")

        # YouTubeæ–‡å­—èµ·ã“ã—
        youtube = summary['youtube_research']
        status_icon = "âœ“" if youtube['status'] == 'success' else "âœ—"
        print(f"\nğŸ¥ YouTubeæ–‡å­—èµ·ã“ã—: {status_icon} {youtube['status'].upper()}")
        if youtube['status'] == 'success':
            print(f"  - å‹•ç”»æ•°: {youtube['videos']}ä»¶")
            print(f"  - æ–‡å­—æ•°: {youtube['characters']:,}æ–‡å­—")
            print(f"  - ç·å†ç”Ÿæ™‚é–“: {youtube['duration_minutes']:.1f}åˆ†")

        # åˆè¨ˆ
        total = summary['total']
        print(f"\nğŸ“ˆ åˆè¨ˆ:")
        print(f"  - ç·æƒ…å ±æº: {total['total_sources']}ä»¶")
        print(f"  - ç·æ–‡å­—æ•°: {total['total_characters']:,}æ–‡å­—")

        print("=" * 60)

    def save_summary(self, summary: Dict, output_path: str):
        """ã‚µãƒãƒªãƒ¼ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ çµ±åˆã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜: {output_path}")
        except Exception as e:
            print(f"âœ— ã‚µãƒãƒªãƒ¼ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)


def main():
    parser = argparse.ArgumentParser(
        description='çµ±åˆãƒªã‚µãƒ¼ãƒãƒ„ãƒ¼ãƒ« - Webãƒªã‚µãƒ¼ãƒ + YouTubeæ–‡å­—èµ·ã“ã—ã‚’ä¸€æ‹¬å®Ÿè¡Œ'
    )

    # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«
    parser.add_argument(
        '--web-urls',
        help='Webã®URLãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆçœç•¥å¯ï¼šWebãƒªã‚µãƒ¼ãƒã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰'
    )
    parser.add_argument(
        '--youtube-urls',
        help='YouTubeã®URLãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆçœç•¥å¯ï¼šYouTubeæ–‡å­—èµ·ã“ã—ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰'
    )

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
    parser.add_argument(
        '--web-output',
        default='web_research.json',
        help='Webãƒªã‚µãƒ¼ãƒã®å‡ºåŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: web_research.jsonï¼‰'
    )
    parser.add_argument(
        '--youtube-output',
        default='youtube_transcripts.json',
        help='YouTubeæ–‡å­—èµ·ã“ã—ã®å‡ºåŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: youtube_transcripts.jsonï¼‰'
    )
    parser.add_argument(
        '--summary-output',
        default='research_summary.json',
        help='çµ±åˆã‚µãƒãƒªãƒ¼ã®å‡ºåŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: research_summary.jsonï¼‰'
    )

    # YouTubeå­—å¹•è¨€èª
    parser.add_argument(
        '--languages',
        nargs='+',
        default=['ja', 'en'],
        help='YouTubeå­—å¹•ã®è¨€èªã‚³ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ja enï¼‰'
    )

    args = parser.parse_args()

    # å°‘ãªãã¨ã‚‚1ã¤ã®å…¥åŠ›ãŒå¿…è¦
    if not args.web_urls and not args.youtube_urls:
        parser.error("--web-urls ã¾ãŸã¯ --youtube-urls ã®ã„ãšã‚Œã‹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")

    tool = UnifiedResearchTool()

    print("=" * 60)
    print("ğŸš€ çµ±åˆãƒªã‚µãƒ¼ãƒãƒ„ãƒ¼ãƒ« - å·¥ç¨‹1A + 1B")
    print("=" * 60)
    print(f"å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    # Webãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ
    web_data = None
    if args.web_urls:
        web_data = tool.run_web_research(args.web_urls, args.web_output)
    else:
        print("ğŸ“š Webãƒªã‚µãƒ¼ãƒã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆ--web-urls ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼‰\n")

    # YouTubeæ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œ
    youtube_data = None
    if args.youtube_urls:
        youtube_data = tool.run_youtube_research(
            args.youtube_urls,
            args.youtube_output,
            args.languages
        )
    else:
        print("ğŸ¥ YouTubeæ–‡å­—èµ·ã“ã—ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆ--youtube-urls ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼‰\n")

    # ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆãƒ»è¡¨ç¤ºãƒ»ä¿å­˜
    summary = tool.generate_summary(web_data, youtube_data)
    tool.print_summary(summary)
    tool.save_summary(summary, args.summary_output)

    # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®æ¡ˆå†…
    print("\n" + "=" * 60)
    print("ğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("=" * 60)
    print("ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§è¬›åº§ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆã§ãã¾ã™:\n")

    cmd_parts = [
        "python3 course_plan_parser.py",
        '  --csv "è‡ªå‹•R7.11 è¬›åº§è¨ˆç”»è¡¨.csv"',
        '  --course "è¬›åº§å"',
        '  --format canvas-script',
        '  --learner_profile "å—è¬›è€…åƒ"',
        '  --target_behavior "åˆ°é”ç›®æ¨™"',
        '  --duration "30åˆ†"',
        '  --tone "ãƒˆãƒ¼ãƒ³"'
    ]

    if web_data:
        cmd_parts.append(f'  --web-research "{args.web_output}"')
    if youtube_data:
        cmd_parts.append(f'  --youtube-research "{args.youtube_output}"')

    cmd_parts.append('  > gemini_prompt.txt')

    print(" \\\n".join(cmd_parts))
    print("\n" + "=" * 60)

    # çµ‚äº†ã‚³ãƒ¼ãƒ‰ã‚’è¨­å®š
    if not web_data and not youtube_data:
        sys.exit(1)  # ä¸¡æ–¹å¤±æ•—
    elif (args.web_urls and not web_data) or (args.youtube_urls and not youtube_data):
        sys.exit(2)  # éƒ¨åˆ†çš„ã«å¤±æ•—
    else:
        sys.exit(0)  # æˆåŠŸ


if __name__ == '__main__':
    main()
